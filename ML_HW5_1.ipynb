{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOT4sgM/Kz+O3ZwgL3DfB0U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jcain17/Intro_to_ML/blob/main/ML_HW5_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 417,
      "metadata": {
        "id": "cE_cZkNX8VMI"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "torch.set_printoptions(edgeitems=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make dataset\n",
        "tc = [0.5,14.0,15.0,28.0,11.0,8.0,3.0,-4.0,6.0,13.0,21.0]\n",
        "tu = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
        "# make tensors\n",
        "tc = torch.tensor(tc)\n",
        "tu = torch.tensor(tu)\n",
        "tun = 0.01 * tu"
      ],
      "metadata": {
        "id": "BWIIY_18A7Ga"
      },
      "execution_count": 418,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nonlin(tu, w1, w2, b):\n",
        "  return w2*tu**2 + w1*tu + b\n",
        "\n",
        "def lin(tu, w, b):\n",
        "  return w * tu + b"
      ],
      "metadata": {
        "id": "gyPErDQLCGPV"
      },
      "execution_count": 419,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = torch.ones(())\n",
        "w2 = torch.ones(())\n",
        "b = torch.ones(())\n",
        "w = torch.ones(())\n",
        "\n",
        "tp = nonlin(tu, w1, w2, b)\n",
        "tp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAlMsywTD52G",
        "outputId": "bac8a532-2209-40bb-e43e-1d124b076706"
      },
      "execution_count": 420,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1311.1901, 3181.7100, 3446.4399, 6790.5103, 3226.9900, 2441.1101,\n",
              "        1184.1101,  498.0399, 2391.9600, 3709.5601, 4747.9600])"
            ]
          },
          "metadata": {},
          "execution_count": 420
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tp = lin(tu, w, b)\n",
        "tp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czxZHEo2odqs",
        "outputId": "ee53b14c-3b9d-4c99-806c-8c4d164a1e7a"
      },
      "execution_count": 421,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([36.7000, 56.9000, 59.2000, 82.9000, 57.3000, 49.9000, 34.9000, 22.8000,\n",
              "        49.4000, 61.4000, 69.4000])"
            ]
          },
          "metadata": {},
          "execution_count": 421
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fun(tp, tc):\n",
        "  diff = (tp - tc)**2\n",
        "  return diff.mean()"
      ],
      "metadata": {
        "id": "ZBibqhPbE0w1"
      },
      "execution_count": 422,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 0.0, 0.0], requires_grad=True)\n",
        "\n",
        "learning_rate = 0.00001\n",
        "nonlinopt = optim.SGD([params], lr= learning_rate)"
      ],
      "metadata": {
        "id": "IZ7gBCbMHFri"
      },
      "execution_count": 423,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nonlintp = nonlin(tu, *params)\n",
        "\n",
        "nonlinloss = loss_fun(nonlintp, tc)\n",
        "nonlinloss.backward()\n",
        "\n",
        "nonlinopt.step()\n",
        "\n",
        "params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xifLbd5HKVl",
        "outputId": "021186b2-82f8-4527-e545-635b9b117a9b"
      },
      "execution_count": 424,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9.5483e-01, -2.6670e+00, -8.2600e-04], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 424
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lin_param = torch.tensor([1.0, 0.0], requires_grad=True)\n",
        "\n",
        "linopt = optim.SGD([lin_param], lr = learning_rate)"
      ],
      "metadata": {
        "id": "RQnJqNrohIHh"
      },
      "execution_count": 425,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lintp = lin(tu, *lin_param)\n",
        "\n",
        "linloss = loss_fun(lintp, tc)\n",
        "linloss.backward()\n",
        "\n",
        "linopt.step()\n",
        "\n",
        "lin_param"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzcAQSQ8g3CE",
        "outputId": "87f0d888-c036-46dd-9473-61ae5e74285a"
      },
      "execution_count": 426,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9.5483e-01, -8.2600e-04], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 426
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(n_epochs, optimizer, params, tu, tc):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    tp = nonlin(tu, *params)\n",
        "    loss = loss_fun(tp, tc)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "      print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
        "\n",
        "  return params"
      ],
      "metadata": {
        "id": "W4jO_xvkJb7X"
      },
      "execution_count": 427,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lintrain_loop(n_epochs, optimizer, lin_param, tu, tc):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    tp = lin(tu, *lin_param)\n",
        "    loss = loss_fun(tp, tc)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "      print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
        "\n",
        "  return lin_param"
      ],
      "metadata": {
        "id": "50X05pgXZHy8"
      },
      "execution_count": 428,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training A: learning rate = 0.1\n",
        "n_epoch = 5000\n",
        "learn_rate = 0.1\n",
        "optimizer = optim.SGD([params], lr = learn_rate)\n",
        "\n",
        "train_loop(n_epoch, optimizer, params, tun, tc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ER98sbJ9KgtV",
        "outputId": "b6cc069b-621e-4f3e-8778-e35fa4952dff"
      },
      "execution_count": 429,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Loss 2.113502\n",
            "Epoch 1000, Loss 2.093012\n",
            "Epoch 1500, Loss 2.092790\n",
            "Epoch 2000, Loss 2.092597\n",
            "Epoch 2500, Loss 2.092420\n",
            "Epoch 3000, Loss 2.092261\n",
            "Epoch 3500, Loss 2.092117\n",
            "Epoch 4000, Loss 2.091986\n",
            "Epoch 4500, Loss 2.091866\n",
            "Epoch 5000, Loss 2.091761\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 25.7966,  27.3118, -10.8946], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 429
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training B: learning rate = 0.01\n",
        "n_epoch = 5000\n",
        "learn_rate = 0.01\n",
        "optimizer = optim.SGD([params], lr = learn_rate)\n",
        "\n",
        "train_loop(n_epoch, optimizer, params, tun, tc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRgLWBW3LaCO",
        "outputId": "ed9673d1-1c65-4388-8cca-9e10d99745a9"
      },
      "execution_count": 430,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Loss 2.091751\n",
            "Epoch 1000, Loss 2.091741\n",
            "Epoch 1500, Loss 2.091730\n",
            "Epoch 2000, Loss 2.091721\n",
            "Epoch 2500, Loss 2.091711\n",
            "Epoch 3000, Loss 2.091702\n",
            "Epoch 3500, Loss 2.091692\n",
            "Epoch 4000, Loss 2.091684\n",
            "Epoch 4500, Loss 2.091674\n",
            "Epoch 5000, Loss 2.091665\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 25.7485,  27.3592, -10.8836], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 430
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training C: learning rate = 0.001\n",
        "n_epoch = 5000\n",
        "learn_rate = 0.001\n",
        "optimizer = optim.SGD([params], lr = learn_rate)\n",
        "\n",
        "train_loop(n_epoch, optimizer, params, tun, tc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDrpxgQoLarb",
        "outputId": "23801505-a347-4a30-947b-4307311961c2"
      },
      "execution_count": 431,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Loss 2.091664\n",
            "Epoch 1000, Loss 2.091664\n",
            "Epoch 1500, Loss 2.091664\n",
            "Epoch 2000, Loss 2.091664\n",
            "Epoch 2500, Loss 2.091664\n",
            "Epoch 3000, Loss 2.091664\n",
            "Epoch 3500, Loss 2.091664\n",
            "Epoch 4000, Loss 2.091664\n",
            "Epoch 4500, Loss 2.091664\n",
            "Epoch 5000, Loss 2.091664\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 25.7484,  27.3592, -10.8836], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 431
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training D: learning rate = 0.0001\n",
        "n_epoch = 5000\n",
        "learn_rate = 0.0001\n",
        "optimizer = optim.SGD([params], lr = learn_rate)\n",
        "\n",
        "train_loop(n_epoch, optimizer, params, tun, tc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQEqZIoiLbb6",
        "outputId": "e859aef1-e0f8-4a0a-ace4-4360a68910c7"
      },
      "execution_count": 432,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Loss 2.091664\n",
            "Epoch 1000, Loss 2.091664\n",
            "Epoch 1500, Loss 2.091664\n",
            "Epoch 2000, Loss 2.091664\n",
            "Epoch 2500, Loss 2.091664\n",
            "Epoch 3000, Loss 2.091664\n",
            "Epoch 3500, Loss 2.091664\n",
            "Epoch 4000, Loss 2.091664\n",
            "Epoch 4500, Loss 2.091664\n",
            "Epoch 5000, Loss 2.091664\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 25.7484,  27.3592, -10.8836], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 432
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Training A: learning rate = 0.1\n",
        "n_epoch = 5000\n",
        "learn_rate = 0.1\n",
        "optimizer = optim.SGD([lin_param], lr = learn_rate)\n",
        "\n",
        "lintrain_loop(n_epoch, optimizer, lin_param, tun, tc)"
      ],
      "metadata": {
        "id": "Ededs0jpPGRc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0237bc7-f893-4803-c5eb-301410bed5b3"
      },
      "execution_count": 433,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Loss 3.988030\n",
            "Epoch 1000, Loss 2.946082\n",
            "Epoch 1500, Loss 2.927962\n",
            "Epoch 2000, Loss 2.927649\n",
            "Epoch 2500, Loss 2.927644\n",
            "Epoch 3000, Loss 2.927644\n",
            "Epoch 3500, Loss 2.927644\n",
            "Epoch 4000, Loss 2.927644\n",
            "Epoch 4500, Loss 2.927644\n",
            "Epoch 5000, Loss 2.927644\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 53.6767, -17.3045], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 433
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Training B: learning rate = 0.01\n",
        "n_epoch = 5000\n",
        "learn_rate = 0.01\n",
        "optimizer = optim.SGD([lin_param], lr = learn_rate)\n",
        "\n",
        "lintrain_loop(n_epoch, optimizer, lin_param, tun, tc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPHoPVTaZgh5",
        "outputId": "3a003259-fc3a-4cde-a5df-19101d240b36"
      },
      "execution_count": 434,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Loss 2.927644\n",
            "Epoch 1000, Loss 2.927644\n",
            "Epoch 1500, Loss 2.927644\n",
            "Epoch 2000, Loss 2.927644\n",
            "Epoch 2500, Loss 2.927644\n",
            "Epoch 3000, Loss 2.927644\n",
            "Epoch 3500, Loss 2.927644\n",
            "Epoch 4000, Loss 2.927644\n",
            "Epoch 4500, Loss 2.927644\n",
            "Epoch 5000, Loss 2.927644\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 53.6767, -17.3045], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 434
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Training C: learning rate = 0.001\n",
        "n_epoch = 5000\n",
        "learn_rate = 0.001\n",
        "optimizer = optim.SGD([lin_param], lr = learn_rate)\n",
        "\n",
        "lintrain_loop(n_epoch, optimizer, lin_param, tun, tc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qr2Gvl0NZsC0",
        "outputId": "05c87a7d-1d56-4389-b451-9d7f3c20f1d8"
      },
      "execution_count": 435,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Loss 2.927644\n",
            "Epoch 1000, Loss 2.927644\n",
            "Epoch 1500, Loss 2.927644\n",
            "Epoch 2000, Loss 2.927644\n",
            "Epoch 2500, Loss 2.927644\n",
            "Epoch 3000, Loss 2.927644\n",
            "Epoch 3500, Loss 2.927644\n",
            "Epoch 4000, Loss 2.927644\n",
            "Epoch 4500, Loss 2.927644\n",
            "Epoch 5000, Loss 2.927644\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 53.6767, -17.3045], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 435
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Training D: learning rate = 0.0001\n",
        "n_epoch = 5000\n",
        "learn_rate = 0.0001\n",
        "optimizer = optim.SGD([lin_param], lr = learn_rate)\n",
        "\n",
        "lintrain_loop(n_epoch, optimizer, lin_param, tun, tc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpHVzvRbZvxg",
        "outputId": "0637d47e-d764-4ad9-8532-8ea09b9008f5"
      },
      "execution_count": 436,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Loss 2.927644\n",
            "Epoch 1000, Loss 2.927644\n",
            "Epoch 1500, Loss 2.927644\n",
            "Epoch 2000, Loss 2.927644\n",
            "Epoch 2500, Loss 2.927644\n",
            "Epoch 3000, Loss 2.927644\n",
            "Epoch 3500, Loss 2.927644\n",
            "Epoch 4000, Loss 2.927644\n",
            "Epoch 4500, Loss 2.927644\n",
            "Epoch 5000, Loss 2.927644\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 53.6767, -17.3045], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 436
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ADAM Training Non-Linear A: learning rate = 0.1\n",
        "\n",
        "n_epochs = 5000\n",
        "learn_rate = 0.1\n",
        "optimizer = optim.Adam([params], lr = learn_rate)\n",
        "\n",
        "train_loop(n_epoch, optimizer, params, tun, tc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMtFweoJbX_E",
        "outputId": "8728e59b-624c-4e11-d669-f842ec918bd5"
      },
      "execution_count": 437,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Loss 2.090718\n",
            "Epoch 1000, Loss 2.090719\n",
            "Epoch 1500, Loss 2.090719\n",
            "Epoch 2000, Loss 2.090998\n",
            "Epoch 2500, Loss 2.090719\n",
            "Epoch 3000, Loss 2.090718\n",
            "Epoch 3500, Loss 2.090719\n",
            "Epoch 4000, Loss 2.090718\n",
            "Epoch 4500, Loss 2.090717\n",
            "Epoch 5000, Loss 2.090765\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 24.7657,  28.3096, -10.6443], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 437
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ADAM Training Non-Linear B: learning rate = 0.01\n",
        "\n",
        "n_epochs = 5000\n",
        "learn_rate = 0.01\n",
        "optimizer = optim.Adam([params], lr = learn_rate)\n",
        "\n",
        "train_loop(n_epoch, optimizer, params, tun, tc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIarR-3fcBRe",
        "outputId": "2417fd80-e21e-406c-9252-1f1e552e6db6"
      },
      "execution_count": 438,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Loss 2.090719\n",
            "Epoch 1000, Loss 2.090718\n",
            "Epoch 1500, Loss 2.090718\n",
            "Epoch 2000, Loss 2.090717\n",
            "Epoch 2500, Loss 2.090717\n",
            "Epoch 3000, Loss 2.090718\n",
            "Epoch 3500, Loss 2.090719\n",
            "Epoch 4000, Loss 2.090718\n",
            "Epoch 4500, Loss 2.090718\n",
            "Epoch 5000, Loss 2.090718\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 24.7604,  28.3043, -10.6496], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 438
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ADAM Training Non-Linear C: learning rate = 0.001\n",
        "\n",
        "n_epochs = 5000\n",
        "learn_rate = 0.001\n",
        "optimizer = optim.Adam([params], lr = learn_rate)\n",
        "\n",
        "train_loop(n_epoch, optimizer, params, tun, tc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpH2s0X3cEzT",
        "outputId": "c2ca6430-549d-4aa9-8702-17e3f0828dd8"
      },
      "execution_count": 439,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Loss 2.090718\n",
            "Epoch 1000, Loss 2.090719\n",
            "Epoch 1500, Loss 2.090717\n",
            "Epoch 2000, Loss 2.090718\n",
            "Epoch 2500, Loss 2.090718\n",
            "Epoch 3000, Loss 2.090718\n",
            "Epoch 3500, Loss 2.090718\n",
            "Epoch 4000, Loss 2.090718\n",
            "Epoch 4500, Loss 2.090718\n",
            "Epoch 5000, Loss 2.090718\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 24.7604,  28.3043, -10.6496], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 439
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ADAM Training Non-Linear D: learning rate = 0.0001\n",
        "\n",
        "n_epochs = 5000\n",
        "learn_rate = 0.0001\n",
        "optimizer = optim.Adam([params], lr = learn_rate)\n",
        "\n",
        "train_loop(n_epoch, optimizer, params, tun, tc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjFPCXFecI96",
        "outputId": "71d5dfea-a735-4a94-ed64-38291b860b9a"
      },
      "execution_count": 440,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Loss 2.090718\n",
            "Epoch 1000, Loss 2.090718\n",
            "Epoch 1500, Loss 2.090719\n",
            "Epoch 2000, Loss 2.090717\n",
            "Epoch 2500, Loss 2.090718\n",
            "Epoch 3000, Loss 2.090717\n",
            "Epoch 3500, Loss 2.090719\n",
            "Epoch 4000, Loss 2.090717\n",
            "Epoch 4500, Loss 2.090719\n",
            "Epoch 5000, Loss 2.090719\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 24.7604,  28.3043, -10.6496], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 440
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ADAM Training Linear A: learning rate = 0.1\n",
        "\n",
        "n_epochs = 5000\n",
        "learn_rate = 0.1\n",
        "optimizer = optim.Adam([lin_param], lr = learn_rate)\n",
        "\n",
        "lintrain_loop(n_epoch, optimizer, lin_param, tun, tc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJH5k0X2cMWv",
        "outputId": "3974fe3e-0a66-4a4b-c45e-b2576e6ed752"
      },
      "execution_count": 441,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Loss 2.927643\n",
            "Epoch 1000, Loss 2.927644\n",
            "Epoch 1500, Loss 2.927664\n",
            "Epoch 2000, Loss 2.927643\n",
            "Epoch 2500, Loss 2.927642\n",
            "Epoch 3000, Loss 2.927644\n",
            "Epoch 3500, Loss 2.927642\n",
            "Epoch 4000, Loss 2.927644\n",
            "Epoch 4500, Loss 2.927644\n",
            "Epoch 5000, Loss 2.927644\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 53.6773, -17.3047], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 441
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ADAM Training Linear B: learning rate = 0.01\n",
        "\n",
        "n_epochs = 5000\n",
        "learn_rate = 0.01\n",
        "optimizer = optim.Adam([lin_param], lr = learn_rate)\n",
        "\n",
        "lintrain_loop(n_epoch, optimizer, lin_param, tun, tc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXXMXl9ocZLa",
        "outputId": "4670f39b-44f0-4ae2-9c59-a799a45bb09c"
      },
      "execution_count": 442,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Loss 2.927643\n",
            "Epoch 1000, Loss 2.927643\n",
            "Epoch 1500, Loss 2.927643\n",
            "Epoch 2000, Loss 2.927644\n",
            "Epoch 2500, Loss 2.927642\n",
            "Epoch 3000, Loss 2.927644\n",
            "Epoch 3500, Loss 2.927643\n",
            "Epoch 4000, Loss 2.927644\n",
            "Epoch 4500, Loss 2.927643\n",
            "Epoch 5000, Loss 2.927646\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 53.6764, -17.3056], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 442
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ADAM Training Linear C: learning rate = 0.001\n",
        "\n",
        "n_epochs = 5000\n",
        "learn_rate = 0.001\n",
        "optimizer = optim.Adam([lin_param], lr = learn_rate)\n",
        "\n",
        "lintrain_loop(n_epoch, optimizer, lin_param, tun, tc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqZodXmbceHZ",
        "outputId": "3c6efc0c-e320-46a7-9753-4c9127664b47"
      },
      "execution_count": 443,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Loss 2.927643\n",
            "Epoch 1000, Loss 2.927643\n",
            "Epoch 1500, Loss 2.927642\n",
            "Epoch 2000, Loss 2.927643\n",
            "Epoch 2500, Loss 2.927642\n",
            "Epoch 3000, Loss 2.927644\n",
            "Epoch 3500, Loss 2.927643\n",
            "Epoch 4000, Loss 2.927643\n",
            "Epoch 4500, Loss 2.927644\n",
            "Epoch 5000, Loss 2.927643\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 53.6772, -17.3048], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 443
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ADAM Training Linear D: learning rate = 0.0001\n",
        "\n",
        "n_epochs = 5000\n",
        "learn_rate = 0.0001\n",
        "optimizer = optim.Adam([lin_param], lr = learn_rate)\n",
        "\n",
        "lintrain_loop(n_epoch, optimizer, lin_param, tun, tc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUfT-YjHcg8L",
        "outputId": "32785096-98b0-47ba-e9e2-219c51f32803"
      },
      "execution_count": 444,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Loss 2.927643\n",
            "Epoch 1000, Loss 2.927643\n",
            "Epoch 1500, Loss 2.927643\n",
            "Epoch 2000, Loss 2.927643\n",
            "Epoch 2500, Loss 2.927643\n",
            "Epoch 3000, Loss 2.927643\n",
            "Epoch 3500, Loss 2.927643\n",
            "Epoch 4000, Loss 2.927643\n",
            "Epoch 4500, Loss 2.927643\n",
            "Epoch 5000, Loss 2.927643\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 53.6772, -17.3048], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 444
        }
      ]
    }
  ]
}